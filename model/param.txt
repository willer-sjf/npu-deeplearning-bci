class TemporalAttentionNet(nn.Module):
    def __init__(
        self, 
        in_channel=3,
        sequence_lens=1000,
        time_lens=10, 
        hidden_size=256, 
        hidden_attention_size=128,
        output_size=2, 
        layer_size=1, 
        bidirectional=True
    ):
        self.subconv = SubConvNet(in_channel=3, out_channel=4)
    
class SpacialAttentionNet(nn.Module):
    def __init__(
        self,
        in_channel=3,
        sequence_lens=1000,
        time_lens=10, 
        hidden_size=256, 
        hidden_attention_size=512,
        output_size=2, 
        layer_size=1, 
        bidirectional=True
    ): 
        self.subconv = SubConvNet(in_channel=1, out_channel=2)
        
class FrequencyAttentionNet(nn.Module):
    
    def __init__(
        self, 
        in_channel=3,
        sequence_lens=1000,
        time_lens=10, 
        output_size=2,
        feature_size=256,
        band_size=3,
    ):
        sub_net = SubFeatureNet(sequence_lens=sequence_lens,
                        time_lens=10, 
                        hidden_size=256, 
                        layer_size=1, 
                        feature_size=feature_size,
                        bidirectional=True)